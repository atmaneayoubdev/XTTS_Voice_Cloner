{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atmaneayoubdev/XTTS_Voice_Cloner/blob/main/colab-notebook/XTTS_Voice_Cloner_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eef9665",
      "metadata": {
        "id": "2eef9665"
      },
      "source": [
        "# 沁､ XTTS Voice Cloner - Gradio Web Interface\n",
        "\n",
        "Welcome to the XTTS Voice Cloner! This notebook creates a web interface that allows you to:\n",
        "\n",
        "- **Upload reference audio** (your voice sample)\n",
        "- **Input text script** (what you want the AI to say)\n",
        "- **Generate cloned speech** using XTTS v2 model\n",
        "- **Play and download** the generated audio\n",
        "\n",
        "## 笞｡ Features\n",
        "- High-quality voice cloning using XTTS v2\n",
        "- Support for 16+ languages\n",
        "- GPU acceleration (when available)\n",
        "- User-friendly web interface\n",
        "- No coding required for end users\n",
        "\n",
        "## 泅 Perfect for:\n",
        "- Content creators\n",
        "- Voiceovers\n",
        "- Audiobook narration\n",
        "- Educational content\n",
        "- Accessibility tools\n",
        "\n",
        "---\n",
        "\n",
        "**Important:** This runs completely in Google Colab - no local installation required!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95221320",
      "metadata": {
        "id": "95221320"
      },
      "source": [
        "## 沒ｦ Step 1: Install Required Dependencies\n",
        "\n",
        "First, we'll install all the necessary packages. This may take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5e5da9db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e5da9db",
        "outputId": "072e8e57-d33e-40fe-eff1-b0ec8eba76cf",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchaudio==2.6.0+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0+cu124) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0+cu124) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0+cu124) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0+cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0+cu124) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.2.0 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0+cu124) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.6.0+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.6.0+cu124) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.6.0+cu124) (3.0.3)\n",
            "Downloading https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (768.4 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m768.4/768.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu124/nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.2.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (166.7 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m166.7/166.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.6.0+cu124 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0+cu124 torchaudio-2.6.0+cu124 triton-3.2.0\n",
            "Collecting coqui-tts\n",
            "  Downloading coqui_tts-0.27.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting anyascii>=0.3.0 (from coqui-tts)\n",
            "  Downloading anyascii-0.3.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting coqpit-config<0.3.0,>=0.2.0 (from coqui-tts)\n",
            "  Downloading coqpit_config-0.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting coqui-tts-trainer<0.4.0,>=0.3.0 (from coqui-tts)\n",
            "  Downloading coqui_tts_trainer-0.3.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: cython>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (3.0.12)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (0.8.1)\n",
            "Collecting encodec>=0.1.1 (from coqui-tts)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2023.6.0->coqui-tts) (2025.3.0)\n",
            "Collecting gruut>=2.4.0 (from gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading gruut-2.4.0.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (7.5.0)\n",
            "Requirement already satisfied: librosa>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (0.11.0)\n",
            "Requirement already satisfied: matplotlib>=3.8.4 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (3.10.0)\n",
            "Collecting monotonic-alignment-search>=0.1.0 (from coqui-tts)\n",
            "  Downloading monotonic_alignment_search-0.2.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting num2words>=0.5.14 (from coqui-tts)\n",
            "  Downloading num2words-0.5.14-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numba>=0.58.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (2.0.2)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (25.0)\n",
            "Collecting pysbd>=0.3.4 (from coqui-tts)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (1.16.2)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (0.13.1)\n",
            "Requirement already satisfied: torch<2.9,>=2.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio<2.9,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (4.67.1)\n",
            "Collecting transformers<4.56,>=4.52.1 (from coqui-tts)\n",
            "  Downloading transformers-4.55.4-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from coqui-tts) (4.15.0)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.12/dist-packages (from coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (5.9.5)\n",
            "Requirement already satisfied: tensorboard>=2.17.0 in /usr/local/lib/python3.12/dist-packages (from coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (2.19.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2023.6.0->coqui-tts) (3.13.1)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts) (2.17.0)\n",
            "Collecting dateparser~=1.1.1 (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gruut-ipa<1.0,>=0.12.0 (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading gruut_lang_en-2.0.1.tar.gz (15.3 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: networkx>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts) (3.5)\n",
            "Collecting python-crfsuite~=0.9.7 (from gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading gruut_lang_de-2.0.1.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading gruut_lang_es-2.0.1.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]>=2.4.0->coqui-tts)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.12/dist-packages (from inflect>=5.6.0->coqui-tts) (10.8.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from inflect>=5.6.0->coqui-tts) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.11.0->coqui-tts) (1.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8.4->coqui-tts) (2.9.0.post0)\n",
            "Collecting docopt>=0.6.2 (from num2words>=0.5.14->coqui-tts)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.58.0->coqui-tts) (0.43.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.0->coqui-tts) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (3.20.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.9,>=2.1->coqui-tts) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch<2.9,>=2.1->coqui-tts) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers<4.56,>=4.52.1->coqui-tts) (0.35.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<4.56,>=4.52.1->coqui-tts) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<4.56,>=4.52.1->coqui-tts) (2.32.4)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<4.56,>=4.52.1->coqui-tts)\n",
            "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<4.56,>=4.52.1->coqui-tts) (0.6.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2023.6.0->coqui-tts) (1.22.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.0->coqui-tts) (2.23)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from dateparser~=1.1.1->gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts) (2025.2)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from dateparser~=1.1.1->gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts) (5.3.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<4.56,>=4.52.1->coqui-tts) (1.1.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from jsonlines~=1.2.0->gruut>=2.4.0->gruut[de,es,fr]>=2.4.0->coqui-tts) (1.17.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.11.0->coqui-tts) (4.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.56,>=4.52.1->coqui-tts) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.56,>=4.52.1->coqui-tts) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.56,>=4.52.1->coqui-tts) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<4.56,>=4.52.1->coqui-tts) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa>=0.11.0->coqui-tts) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.17.0->coqui-tts-trainer<0.4.0,>=0.3.0->coqui-tts) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.9,>=2.1->coqui-tts) (3.0.3)\n",
            "Downloading coqui_tts-0.27.2-py3-none-any.whl (858 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m858.4/858.4 kB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyascii-0.3.3-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m345.1/345.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coqpit_config-0.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading coqui_tts_trainer-0.3.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic_alignment_search-0.2.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (648 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m648.4/648.4 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading num2words-0.5.14-py3-none-any.whl (163 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.55.4-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m139.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading python_crfsuite-0.9.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: encodec, gruut, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=4d9239dc931c456a77624e9fcfb720c36ce2706e36e480947a21a306392b14f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/eb/9f/e13610cc46ab39d3199fbabebd1c3e142d44b679526e0f228a\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.4.0-py3-none-any.whl size=86758 sha256=fec88e92b364d59b6a3efdd89bee2f08aee1be1ec5eac94fe87029faed7059d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/93/9c/fbd0d8778ac586a48a20e73d2a64d882984d9501fd5e8daf24\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=15c4809e00c1a295331d392cc26f1decb93797beecc500f8dceff1c0cb254a54\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104873 sha256=f3eae237d26438b32d2f11612372ff3cc934ea1f4bf909211f0ec8861d787ba8\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/9d/d2/d6f6eb77784f063fcd497427fd93324cebf974247984bba85b\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.1-py3-none-any.whl size=18498314 sha256=f421c1194102d76492cf4e85b7ce022736a83eec21fac878f6826fabf798ec16\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/75/26/e627d52dac0253ad7d11e5b9f74d51d82e040d07432f53ad9b\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.1-py3-none-any.whl size=15326858 sha256=a3d8f1b9e43c2bf75190f7ac23743122f8e9092bdfb9da225ce1bf5a03b241ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/ca/a4/d1a6f20e47b857313689ca1f31684102ba67cecda2acae368d\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.1-py3-none-any.whl size=32173927 sha256=c7fdf4059bc01cfe6833432bc6e07e45a485b707cfdc043e7df451124c4e1a4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/19/79/0a65f77c4921ae0daa8d01e5b11502a909b55bd22fa188962d\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968767 sha256=e4932fb935a3009fb877a67baadb43432d769202a604528ea3f29464f07e6db6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/91/46/0ab326f9e46bc2cc2fe2f35b0e0e6f3b8284d78efd25192d96\n",
            "Successfully built encodec gruut docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr\n",
            "Installing collected packages: gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, python-crfsuite, pysbd, num2words, monotonic-alignment-search, jsonlines, gruut-ipa, coqpit-config, anyascii, dateparser, tokenizers, gruut, transformers, coqui-tts-trainer, encodec, coqui-tts\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.1\n",
            "    Uninstalling tokenizers-0.22.1:\n",
            "      Successfully uninstalled tokenizers-0.22.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.1\n",
            "    Uninstalling transformers-4.57.1:\n",
            "      Successfully uninstalled transformers-4.57.1\n",
            "Successfully installed anyascii-0.3.3 coqpit-config-0.2.1 coqui-tts-0.27.2 coqui-tts-trainer-0.3.1 dateparser-1.1.8 docopt-0.6.2 encodec-0.1.1 gruut-2.4.0 gruut-ipa-0.13.0 gruut_lang_de-2.0.1 gruut_lang_en-2.0.1 gruut_lang_es-2.0.1 gruut_lang_fr-2.0.2 jsonlines-1.2.0 monotonic-alignment-search-0.2.1 num2words-0.5.14 pysbd-0.3.4 python-crfsuite-0.9.11 tokenizers-0.21.4 transformers-4.55.4\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (0.25.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "CUDA available: True\n",
            "GPU device: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch==2.6.0+cu124 torchaudio==2.6.0+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install coqui-tts\n",
        "!pip install numpy scipy librosa soundfile pydub matplotlib transformers\n",
        "\n",
        "# Verify GPU is available\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428a981c",
      "metadata": {
        "id": "428a981c"
      },
      "source": [
        "## 沐ｧ Step 2: Import Libraries and initialize XTTS Model\n",
        "Now we'll import all necessary libraries and load the XTTS model. The model download happens automatically on first run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55c1559",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55c1559",
        "outputId": "ca19d80c-8f69-4eed-9ee0-50b08c38128e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torchaudio version: 2.6.0+cu124\n",
            "沒 Libraries imported successfully!\n",
            "沐 Loading XTTS model on cuda...\n",
            "   Attempt 1/3...\n",
            " > You must confirm the following:\n",
            " | > \"I have purchased a commercial license from Coqui: licensing@coqui.ai\"\n",
            " | > \"Otherwise, I agree to the terms of the non-commercial CPML: https://coqui.ai/cpml\" - [y/n]\n",
            " | | > y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺哩| 1.87G/1.87G [00:21<00:00, 97.9MiB/s]\n",
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 1.87G/1.87G [00:21<00:00, 85.1MiB/s]\n",
            "4.37kiB [00:00, 33.7kiB/s]\n",
            "\n",
            "361kiB [00:00, 2.59MiB/s]\n",
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 32.0/32.0 [00:00<00:00, 184iB/s]\n",
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 7.75M/7.75M [00:17<00:00, 53.1MiB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "笨 XTTS model loaded successfully!\n",
            "沁 Voice cloner ready!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import time\n",
        "import torch\n",
        "import torchaudio\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# print the torchaudio version\n",
        "print(f\"Torchaudio version: {torchaudio.__version__}\")\n",
        "\n",
        "# from TTS.api import TTS # Move this import inside the class\n",
        "\n",
        "print(\"沒 Libraries imported successfully!\")\n",
        "\n",
        "# Initialize XTTS model with retry logic\n",
        "class XTTSVoiceCloner:\n",
        "    def __init__(self, max_retries=3):\n",
        "        \"\"\"Initialize XTTS model with robust error handling.\"\"\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.tts = None\n",
        "\n",
        "        print(f\"沐 Loading XTTS model on {self.device}...\")\n",
        "\n",
        "        from TTS.api import TTS # Import TTS here\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                print(f\"   Attempt {attempt + 1}/{max_retries}...\")\n",
        "                self.tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(self.device)\n",
        "                print(\"笨 XTTS model loaded successfully!\")\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"笶 Error loading model (attempt {attempt + 1}): {str(e)}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    print(\"泅ｨ Failed to load model after all retries!\")\n",
        "                    raise e\n",
        "                print(\"竢ｳ Retrying in 10 seconds...\")\n",
        "                time.sleep(10)\n",
        "\n",
        "    def get_supported_languages(self):\n",
        "        \"\"\"Return list of supported languages.\"\"\"\n",
        "        return [\n",
        "            (\"English\", \"en\"), (\"Spanish\", \"es\"), (\"French\", \"fr\"),\n",
        "            (\"German\", \"de\"), (\"Italian\", \"it\"), (\"Portuguese\", \"pt\"),\n",
        "            (\"Polish\", \"pl\"), (\"Turkish\", \"tr\"), (\"Russian\", \"ru\"),\n",
        "            (\"Dutch\", \"nl\"), (\"Czech\", \"cs\"), (\"Arabic\", \"ar\"),\n",
        "            (\"Chinese\", \"zh-cn\"), (\"Japanese\", \"ja\"), (\"Hungarian\", \"hu\"), (\"Korean\", \"ko\")\n",
        "        ]\n",
        "\n",
        "# Initialize the voice cloner\n",
        "voice_cloner = XTTSVoiceCloner()\n",
        "print(\"沁 Voice cloner ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f0ffaf",
      "metadata": {
        "id": "73f0ffaf"
      },
      "source": [
        "## 沁ｵ Step 3: Define Audio Processing Functions\n",
        "\n",
        "These functions handle audio file validation, format conversion, and processing for optimal voice cloning results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba0d2910",
      "metadata": {
        "id": "ba0d2910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd881f13-f6ae-4ec2-dd8e-bb265985195b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "沁ｵ Audio processing functions defined!\n"
          ]
        }
      ],
      "source": [
        "# Audio processing functions\n",
        "def validate_audio_file(audio_file):\n",
        "    \"\"\"Validate uploaded audio file.\"\"\"\n",
        "    if audio_file is None:\n",
        "        return False, \"笶 No audio file uploaded!\"\n",
        "\n",
        "    # Check file size (max 50MB)\n",
        "    file_size = os.path.getsize(audio_file) / (1024 * 1024)  # MB\n",
        "    if file_size > 50:\n",
        "        return False, f\"笶 File too large ({file_size:.1f}MB). Max size: 50MB\"\n",
        "\n",
        "    # Check file extension\n",
        "    valid_extensions = ['.wav', '.mp3', '.flac', '.m4a', '.ogg']\n",
        "    file_ext = os.path.splitext(audio_file)[1].lower()\n",
        "    if file_ext not in valid_extensions:\n",
        "        return False, f\"笶 Unsupported format: {file_ext}. Use: {', '.join(valid_extensions)}\"\n",
        "\n",
        "    return True, \"笨 Audio file is valid!\"\n",
        "\n",
        "def get_audio_info(audio_file):\n",
        "    \"\"\"Get information about the audio file.\"\"\"\n",
        "    try:\n",
        "        import librosa\n",
        "        y, sr = librosa.load(audio_file, sr=None)\n",
        "        duration = len(y) / sr\n",
        "\n",
        "        return {\n",
        "            \"duration\": duration,\n",
        "            \"sample_rate\": sr,\n",
        "            \"channels\": 1 if len(y.shape) == 1 else y.shape[0],\n",
        "            \"format\": os.path.splitext(audio_file)[1][1:].upper()\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "def process_reference_audio(audio_file):\n",
        "    \"\"\"Process and validate reference audio for voice cloning.\"\"\"\n",
        "    if not audio_file:\n",
        "        return None, \"笶 Please upload a reference audio file!\"\n",
        "\n",
        "    # Validate file\n",
        "    is_valid, message = validate_audio_file(audio_file)\n",
        "    if not is_valid:\n",
        "        return None, message\n",
        "\n",
        "    # Get audio info\n",
        "    info = get_audio_info(audio_file)\n",
        "    if \"error\" in info:\n",
        "        return None, f\"笶 Error reading audio: {info['error']}\"\n",
        "\n",
        "    # Check duration (recommend 3-30 seconds)\n",
        "    duration = info[\"duration\"]\n",
        "    if duration < 1:\n",
        "        return None, \"笞ｸ Audio too short! Use 3-30 seconds for best results.\"\n",
        "    elif duration > 60:\n",
        "        return None, \"笞ｸ Audio too long! Use 3-30 seconds for best results.\"\n",
        "\n",
        "    status_msg = f\"笨 Audio processed successfully!\\n\"\n",
        "    status_msg += f\"沒 Duration: {duration:.1f}s | Sample Rate: {info['sample_rate']}Hz | Format: {info['format']}\"\n",
        "\n",
        "    if duration < 3:\n",
        "        status_msg += \"\\n汳｡ Tip: 3-10 seconds of clear speech works best!\"\n",
        "\n",
        "    return audio_file, status_msg\n",
        "\n",
        "print(\"沁ｵ Audio processing functions defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfc00f35",
      "metadata": {
        "id": "bfc00f35"
      },
      "source": [
        "## 泓｣ｸ Step 4: Create Text-to-Speech Generation Function\n",
        "\n",
        "This is the core function that performs voice cloning using the reference audio and input text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a375d03f",
      "metadata": {
        "id": "a375d03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef345713-548b-41c4-b0d4-0246a69241b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "泓｣ｸ Voice cloning function ready!\n"
          ]
        }
      ],
      "source": [
        "# Main voice cloning function for Gradio\n",
        "def clone_voice(reference_audio, input_text, language, progress=gr.Progress()):\n",
        "    \"\"\"\n",
        "    Main function to clone voice using reference audio and input text.\n",
        "\n",
        "    Args:\n",
        "        reference_audio: Uploaded audio file path\n",
        "        input_text: Text to convert to speech\n",
        "        language: Selected language code\n",
        "        progress: Gradio progress tracker\n",
        "\n",
        "    Returns:\n",
        "        tuple: (output_audio_path, status_message)\n",
        "    \"\"\"\n",
        "\n",
        "    # Progress tracking\n",
        "    progress(0.1, desc=\"沐 Validating inputs...\")\n",
        "\n",
        "    # Validate inputs\n",
        "    if not reference_audio:\n",
        "        return None, \"笶 Please upload a reference audio file!\"\n",
        "\n",
        "    if not input_text or len(input_text.strip()) < 5:\n",
        "        return None, \"笶 Please enter text (at least 5 characters)!\"\n",
        "\n",
        "    if len(input_text) > 1000:\n",
        "        return None, \"笶 Text too long! Please keep it under 1000 characters.\"\n",
        "\n",
        "    progress(0.2, desc=\"沁ｵ Processing reference audio...\")\n",
        "\n",
        "    # Process reference audio\n",
        "    processed_audio, audio_status = process_reference_audio(reference_audio)\n",
        "    if not processed_audio:\n",
        "        return None, audio_status\n",
        "\n",
        "    progress(0.4, desc=\"洟 Generating speech...\")\n",
        "\n",
        "    try:\n",
        "        # Create temporary output file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_file:\n",
        "            output_path = tmp_file.name\n",
        "\n",
        "        # Generate speech using XTTS\n",
        "        voice_cloner.tts.tts_to_file(\n",
        "            text=input_text.strip(),\n",
        "            file_path=output_path,\n",
        "            speaker_wav=processed_audio,\n",
        "            language=language\n",
        "        )\n",
        "\n",
        "        progress(0.9, desc=\"笨 Finalizing...\")\n",
        "\n",
        "        # Check if output file was created successfully\n",
        "        if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:\n",
        "            return None, \"笶 Failed to generate audio. Please try again.\"\n",
        "\n",
        "        progress(1.0, desc=\"沁 Complete!\")\n",
        "\n",
        "        # Success message\n",
        "        char_count = len(input_text)\n",
        "        word_count = len(input_text.split())\n",
        "        success_msg = f\"沁 Voice cloning successful!\\n\"\n",
        "        success_msg += f\"沒 Generated {word_count} words ({char_count} characters)\\n\"\n",
        "        success_msg += f\"沁､ Language: {language.upper()}\\n\"\n",
        "        success_msg += f\"沐 Audio ready for playback!\"\n",
        "\n",
        "        return output_path, success_msg\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"笶 Error during voice generation: {str(e)}\"\n",
        "        print(f\"Voice cloning error: {e}\")\n",
        "        return None, error_msg\n",
        "\n",
        "def get_example_text():\n",
        "    \"\"\"Return example text for demonstration.\"\"\"\n",
        "    examples = [\n",
        "        \"Hello! This is a test of the voice cloning system. How do I sound?\",\n",
        "        \"Welcome to our AI voice cloning demo. This technology can replicate voices with just a short audio sample.\",\n",
        "        \"The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.\",\n",
        "        \"In a world where technology advances rapidly, voice cloning represents a fascinating frontier in artificial intelligence.\"\n",
        "    ]\n",
        "    return examples\n",
        "\n",
        "print(\"泓｣ｸ Voice cloning function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd9af10",
      "metadata": {
        "id": "7fd9af10"
      },
      "source": [
        "## 沁ｨ Step 5: Build Gradio Interface Components\n",
        "\n",
        "Now we'll create the user-friendly web interface with all the input and output components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83d40a4f",
      "metadata": {
        "id": "83d40a4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd322bfb-ca82-40e5-ff21-35a69b62c7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "沁ｨ Gradio interface components ready!\n"
          ]
        }
      ],
      "source": [
        "# Create Gradio interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create and configure the Gradio web interface.\"\"\"\n",
        "\n",
        "    # Custom CSS for better styling\n",
        "    custom_css = \"\"\"\n",
        "    .gradio-container {\n",
        "        max-width: 1200px !important;\n",
        "        margin: auto !important;\n",
        "    }\n",
        "    .header {\n",
        "        text-align: center;\n",
        "        margin-bottom: 2rem;\n",
        "    }\n",
        "    .info-box {\n",
        "        background: linear-gradient(45deg, #f0f9ff, #e0f2fe);\n",
        "        padding: 1rem;\n",
        "        border-radius: 8px;\n",
        "        border-left: 4px solid #0ea5e9;\n",
        "        margin: 1rem 0;\n",
        "    }\n",
        "    .info-box li {\n",
        "        color: black !important;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the interface\n",
        "    with gr.Blocks(css=custom_css, title=\"XTTS Voice Cloner\", theme=gr.themes.Soft()) as interface:\n",
        "\n",
        "        # Header\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"header\">\n",
        "            <h1>沁､ XTTS Voice Cloner</h1>\n",
        "            <p style=\"font-size: 1.2em; color: #666;\">\n",
        "                High-quality voice cloning using AI 窶｢ Upload your voice, enter text, get AI speech!\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Instructions\n",
        "        gr.HTML(\"\"\"\n",
        "        <div class=\"info-box \">\n",
        "            <h3 style=\"color: black\">沒 How to use:</h3>\n",
        "            <ol >\n",
        "                <li ><strong style=\"color: black\">Upload Reference Audio:</strong> A clear 3-30 second recording of the target voice</li>\n",
        "                <li><strong style=\"color: black\">Enter Text:</strong> What you want the AI to say (up to 1000 characters)</li>\n",
        "                <li><strong style=\"color: black\">Select Language:</strong> Choose the language for speech generation</li>\n",
        "                <li><strong style=\"color: black\">Generate:</strong> Click the button and wait for the magic! 笨ｨ</li>\n",
        "            </ol>\n",
        "            <p style=\"color: black\"><strong style=\"color: black\">汳｡ Tips:</strong> Use high-quality audio with minimal background noise for best results!</p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                # Input section\n",
        "                gr.HTML(\"<h3>沁ｯ Inputs</h3>\")\n",
        "\n",
        "                # File upload\n",
        "                reference_audio = gr.Audio(\n",
        "                    label=\"沁､ Reference Audio (Upload your voice sample)\",\n",
        "                    type=\"filepath\",\n",
        "                    sources=[\"upload\"],\n",
        "                    interactive=True\n",
        "                )\n",
        "\n",
        "                # Text input\n",
        "                input_text = gr.Textbox(\n",
        "                    label=\"沒 Text to Convert to Speech\",\n",
        "                    placeholder=\"Enter the text you want the AI to speak...\",\n",
        "                    lines=4,\n",
        "                    max_lines=8,\n",
        "                    interactive=True\n",
        "                )\n",
        "\n",
        "                # Language selection\n",
        "                language_choices = voice_cloner.get_supported_languages()\n",
        "                language = gr.Dropdown(\n",
        "                    choices=language_choices,\n",
        "                    value=\"en\",\n",
        "                    label=\"沍 Language\",\n",
        "                    interactive=True\n",
        "                )\n",
        "\n",
        "                # Generate button\n",
        "                generate_btn = gr.Button(\n",
        "                    \"泅 Generate Cloned Voice\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "                # Example texts\n",
        "                gr.HTML(\"<h4>沒 Example Texts:</h4>\")\n",
        "                example_texts = get_example_text()\n",
        "                for i, example in enumerate(example_texts):\n",
        "                    gr.Button(\n",
        "                        f\"Example {i+1}\",\n",
        "                        size=\"sm\"\n",
        "                    ).click(\n",
        "                        lambda x=example: x,\n",
        "                        outputs=input_text\n",
        "                    )\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                # Output section\n",
        "                gr.HTML(\"<h3>沁ｧ Results</h3>\")\n",
        "\n",
        "                # Status display\n",
        "                status_output = gr.Textbox(\n",
        "                    label=\"沒 Status\",\n",
        "                    interactive=False,\n",
        "                    lines=6\n",
        "                )\n",
        "\n",
        "                # Audio player\n",
        "                audio_output = gr.Audio(\n",
        "                    label=\"沐 Generated Speech\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                # Download info\n",
        "                gr.HTML(\"\"\"\n",
        "                <div style=\"background: #f8fafc; padding: 1rem; border-radius: 6px; margin-top: 1rem;\">\n",
        "                    <p style=\"color: black\"><strong style=\"color: black\">汳ｾ Download:</strong> Click the 站ｯ menu in the audio player above to download your generated speech!</p>\n",
        "                </div>\n",
        "                \"\"\")\n",
        "\n",
        "        # Footer\n",
        "        gr.HTML(\"\"\"\n",
        "        <div style=\"text-align: center; margin-top: 2rem; padding: 1rem; border-top: 1px solid #e5e7eb;\">\n",
        "            <p style=\"color: #6b7280;\">\n",
        "                泅 Powered by <strong>XTTS v2</strong> 窶｢\n",
        "                沐ｬ Running on <strong>Google Colab</strong> 窶｢\n",
        "                笶､ｸ Open Source AI\n",
        "            </p>\n",
        "        </div>\n",
        "        \"\"\")\n",
        "\n",
        "        # Connect the generate button\n",
        "        generate_btn.click(\n",
        "            fn=clone_voice,\n",
        "            inputs=[reference_audio, input_text, language],\n",
        "            outputs=[audio_output, status_output],\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "print(\"沁ｨ Gradio interface components ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d63f116",
      "metadata": {
        "id": "6d63f116"
      },
      "source": [
        "## 泅 Step 6: Launch Gradio Web Application\n",
        "\n",
        "Finally, let's launch the web interface! This will create a public URL that you can share with others."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b42070be",
      "metadata": {
        "id": "b42070be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "620f997d-9b29-4c50-fcf3-d77d3f3042de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "泅 Launching XTTS Voice Cloner Web Interface...\n",
            "============================================================\n",
            "笶 Error launching interface: Cannot find empty port in range: 7860-7860. You can specify a different port by setting the GRADIO_SERVER_PORT environment variable or passing the `server_port` parameter to `launch()`.\n",
            "沐 Trying alternative launch...\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d5cae106eea894c7e8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d5cae106eea894c7e8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Launch the Gradio interface\n",
        "print(\"泅 Launching XTTS Voice Cloner Web Interface...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create the interface\n",
        "app = create_gradio_interface()\n",
        "\n",
        "# Launch with public sharing enabled\n",
        "try:\n",
        "    app.launch(\n",
        "        share=True,          # Creates public URL for sharing\n",
        "        inbrowser=True,      # Opens in browser automatically\n",
        "        server_name=\"0.0.0.0\",  # Allow external connections\n",
        "        server_port=7860,    # Default port\n",
        "        show_error=True,     # Show detailed errors\n",
        "        quiet=False          # Show launch info\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"笶 Error launching interface: {e}\")\n",
        "    print(\"沐 Trying alternative launch...\")\n",
        "\n",
        "    # Try alternative launch without inbrowser\n",
        "    app.launch(\n",
        "        share=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        show_error=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fddd8114",
      "metadata": {
        "id": "fddd8114"
      },
      "source": [
        "## 沁 Success! Your Voice Cloner is Running!\n",
        "\n",
        "If everything worked correctly, you should see:\n",
        "1. **Local URL**: `http://localhost:7860` - For your use\n",
        "2. **Public URL**: `https://xxxxxxx.gradio.live` - **Share this link with others!**\n",
        "\n",
        "\n",
        "   ```markdown\n",
        "   # XTTS Voice Cloner\n",
        "   \n",
        "   ## Quick Start\n",
        "   1. Open this notebook in Google Colab\n",
        "   2. Run all cells (Runtime 竊 Run all)\n",
        "   3. Use the web interface that opens\n",
        "   4. Share the public URL with others!\n",
        "   ```\n",
        "\n",
        "3. **Include these requirements** in your repo:\n",
        "   - This notebook file (`.ipynb`)\n",
        "   - README.md with instructions\n",
        "   - requirements.txt (optional, packages are installed in notebook)\n",
        "\n",
        "### 沐ｧ Customization Options:\n",
        "\n",
        "- **Change supported languages**: Modify the `get_supported_languages()` function\n",
        "- **Adjust UI theme**: Change `theme=gr.themes.Soft()` to other Gradio themes\n",
        "- **Add more examples**: Extend the `get_example_text()` function\n",
        "- **Custom styling**: Modify the `custom_css` variable\n",
        "\n",
        "### 泅ｨ Important Notes:\n",
        "\n",
        "- **Colab session expires** after 12 hours of inactivity\n",
        "- **GPU quota is limited** - use efficiently\n",
        "- **Files are temporary** - download results before session ends\n",
        "- **Public URLs expire** when Colab session ends\n",
        "\n",
        "### 沍 Features Available:\n",
        "\n",
        "笨 Voice cloning with any audio sample  \n",
        "笨 16+ language support  \n",
        "笨 Real-time progress tracking  \n",
        "笨 Audio validation and processing  \n",
        "笨 Download generated speech  \n",
        "笨 Mobile-friendly interface  \n",
        "笨 Public sharing capability  \n",
        "\n",
        "**Enjoy your AI voice cloning experience!** 沁､笨ｨ"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pDBV3PtRzYS"
      },
      "id": "6pDBV3PtRzYS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}